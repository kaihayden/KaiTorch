{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5ebfd4c",
   "metadata": {},
   "source": [
    "# [Notebook 02] Reverse-mode Autodiff & Backpropogation\n",
    "\n",
    "### Recapping previous notebooks\n",
    "__Notebook 0__\n",
    "\n",
    "1. The gradient is how changes in an input variable affects the output.\n",
    "\n",
    "2. We can break down complex functions into smaller parts and \"chain\" them together.\n",
    "\n",
    "__Notebook 1__\n",
    "\n",
    "1. We can convert a complex function into a composite function, made up of a chain of simple operations\n",
    "\n",
    "2. We can model a composite function as a simple feed forward neural net with a DAG structure, and calculate the result using a forward pass."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c81e4f6",
   "metadata": {},
   "source": [
    "__So, we've essentially built an unnecessary complicated version of a simple calculator__ - _but we did this for a reason._\n",
    "\n",
    "A calculator is good at taking inputs and spitting out an output. A neural network is good at taking input and output pairs, and iteratively tweaking its weights so that when it takes an input, it spits out the output that we want.\n",
    "\n",
    "In this notebook, we'll bridge the gap and turn our calculator into a neural network in a few steps:\n",
    "\n",
    "1. Understanding the chain rule for calculating gradients\n",
    "\n",
    "2. Defining the derivatives of our base operations\n",
    "\n",
    "3. Implementing reverse-mode automatic differentiation\n",
    "\n",
    "4. Updating weights through backpropogation (future notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6123ad",
   "metadata": {},
   "source": [
    "# The Chain Rule\n",
    "\n",
    "__The chain rule is a method of calculating the gradients of a composite function__\n",
    "\n",
    "This rule is particularly integral to neural networks as it takes advantage of the property that neural networks, which are very complicated functions, can be broken down into a chain of basic operations such as addition and multiplication.\n",
    "\n",
    "This is the chain rule:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af98434a",
   "metadata": {},
   "source": [
    "$$ \\frac{dL}{dx} = \\frac{dL}{dy} \\cdot \\frac{dy}{dx}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa165e7",
   "metadata": {},
   "source": [
    "$L, y, x$ are variables, and I chose those letters to represent different parts of the neural network\n",
    "- $L$ is the $L$oss value :)\n",
    "- $y$ is the output of a node\n",
    "- $x$ is an input of a node\n",
    "\n",
    "More on loss later, but this value is a representation of the \"error\" of our model.\n",
    "\n",
    "If we want to train a network, we need to adjust the value of each weight/variable $x$ in a way that will minimize $L$.\n",
    "\n",
    "Using our gradient notation, how each variable $x$ affects the loss function is written as\n",
    "\n",
    "$$ \\frac{dL}{dx} = \\nabla x$$\n",
    "\n",
    "However, there might be many nested basic functions between our variable $x$ and the final output $L$. This would seem to add a lot of complexity, but the chain rule actually allows us to take advantage of this property.\n",
    "\n",
    "### Chaining Derivatives\n",
    "\n",
    "Let's say input $x$ is used to calculate output $y$, which is used to calculate loss $L$.\n",
    "\n",
    "$$ x \\Rightarrow y \\Rightarrow L $$\n",
    "\n",
    "To calculate the derivative of $L$ with respect to $x$, we can calculate the derivative of $L$ with respect to $y$, multiplied by the derivative of $y$ with respect to $x$.\n",
    "\n",
    "$$ \\frac{dL}{dx} = \\frac{dL}{dy} \\cdot \\frac{dy}{dx}$$\n",
    "\n",
    "Now let's say $a$ is used to calculate $b$, which is used to calculate $c$, which is used to calculate $d$, which is used to calculate $e$, which is used to calculate $L$.\n",
    "\n",
    "$$ a \\Rightarrow b \\Rightarrow c \\Rightarrow d \\Rightarrow e \\Rightarrow L $$\n",
    "\n",
    "The chain rule lets us find how $w$ affects $L$ by calculating:\n",
    "\n",
    "$$ \\frac{dL}{da} = \\frac{dL}{dd} \\cdot \\frac{dd}{dc} \\cdot \\frac{dc}{db} \\cdot \\frac{db}{da}$$\n",
    "\n",
    "__See how for longer sequences, we just create a longer chain of derivative multiplications?__ and since we are using a chain of primitive operations, each of these derivatives is almost trivial. Let's take an example:\n",
    "\n",
    "$$ L = (((((a ^ 2) * 6) - 4) / 3) + 5 $$\n",
    "\n",
    "can be broken down to the following basic operations\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "&L = e + 5\\\\\n",
    "&e = d / 3\\\\\n",
    "&d = c - 4\\\\\n",
    "&c = b * 6\\\\\n",
    "&b = a ^ 2\\\\\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "Chaining the derivatives\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "\\frac{dL}{da} &= \\frac{dL}{de} \\cdot \\frac{de}{dd} \\cdot \\frac{dd}{dc} \\cdot \\frac{dc}{db} \\cdot \\frac{db}{da} \\\\\n",
    "&= 1 \\cdot \\frac{1}{3} \\cdot  1 \\cdot 6 \\cdot 2a\\\\\n",
    "&= 4a\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "double checking our result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7899c628",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(a):\n",
    "    return (((((a**2) * 6) - 4) / 3) + 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c9976dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n"
     ]
    }
   ],
   "source": [
    "eps = 1e-8\n",
    "a = 1\n",
    "rise = f(a+eps) - f(a)\n",
    "run = (a+eps)-a\n",
    "gradient = rise/run\n",
    "print(gradient)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848ca10b",
   "metadata": {},
   "source": [
    "# Reverse-mode Automatic Differentiation\n",
    "\n",
    "Hopefully my explanation of the chain rule makes sense as we move on to reverse-mode autodiff. This term might sound complicated, but its basically starting from the Loss value and recursively applying the chain rule until we find the gradient of every weight and bias (parameter) in the neural network. Let me try to illustrate this idea in a simplified way.\n",
    "\n",
    "__If this is our forward pass__\n",
    "\n",
    "$$ x \\Rightarrow y \\Rightarrow L $$\n",
    "\n",
    "where $x$ is used to calculate $y$, is used to calculate loss $L$.\n",
    "\n",
    "__Then this is our backward pass__\n",
    "1. Start from loss $L$, through `L._prev` we know that it used $y$\n",
    "\n",
    "  - Find the gradient of $y$ using $\\frac{dL}{dy}$\n",
    "\n",
    "2. Through `y._prev` we know $y$ used variable $x$\n",
    "\n",
    "  - Find the gradient of $\\frac{dL}{dx}$ by calculating $\\frac{dL}{dy} \\cdot \\frac{dy}{dx}$\n",
    "  - Since we already calculated $\\frac{dL}{dy}$ in the first step, really we just need to calculate $\\frac{dy}{dx}$ and multiply the two together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2277126",
   "metadata": {},
   "source": [
    "# Implementation\n",
    "\n",
    "Lets add reverse-mode autodiff to KaiTorch, recall our `Scalar` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c701cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kaitorch/core.py\n",
    "\n",
    "import math\n",
    "\n",
    "class Scalar:\n",
    "\n",
    "    def __init__(self, data, _in=(), _op=''):\n",
    "        self.data = data\n",
    "        self.grad = 0.0 # hi :)\n",
    "\n",
    "        self._backward = lambda: None  # hi :)\n",
    "        self._prev = set(_in)\n",
    "        self._op = _op\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f'Value(data={self.data})'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d98205",
   "metadata": {},
   "source": [
    "... and our 5 base operations\n",
    "- Addition\n",
    "- Multiplication\n",
    "- Exponentiation\n",
    "- Natural Exponentiation\n",
    "- Natural Log\n",
    "\n",
    "Let's define the derivative of each one by adding a `_backward()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b15be4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kaitorch/core.py\n",
    "\n",
    "# Addition\n",
    "\n",
    "def __add__(a, b):\n",
    "\n",
    "    a = a if isinstance(a, Scalar) else Scalar(a)\n",
    "    b = b if isinstance(b, Scalar) else Scalar(b)\n",
    "\n",
    "    # Calculation: y = a + b\n",
    "    def _forward():\n",
    "        _a = a.data\n",
    "        _b = b.data\n",
    "        _y = _a + _b\n",
    "        return Scalar(_y, _in=(a, b), _op='+')\n",
    "    y = _forward()\n",
    "\n",
    "    # Derivative: dy/da = 1\n",
    "    # Chain Rule: dL/da = dL/dy * dy/da\n",
    "    #                   = dL/dy\n",
    "    def _backward():\n",
    "        a.grad += y.grad\n",
    "        b.grad += y.grad\n",
    "    y._backward = _backward\n",
    "\n",
    "    return y\n",
    "\n",
    "Scalar.__add__ = __add__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66abe9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kaitorch/core.py\n",
    "\n",
    "# Multiplication\n",
    "def __mul__(a, b):\n",
    "\n",
    "    a = a if isinstance(a, Scalar) else Scalar(a)\n",
    "    b = b if isinstance(b, Scalar) else Scalar(b)\n",
    "\n",
    "    # Calculation: y = a * b\n",
    "    def _forward():\n",
    "        _a = a.data\n",
    "        _b = b.data\n",
    "        _y = _a * _b\n",
    "        return Scalar(_y, _in=(a, b), _op='*')\n",
    "    y = _forward()\n",
    "\n",
    "    # Derivative: dy/da = b\n",
    "    # Chain Rule: dL/da = dL/dy * dy/da\n",
    "    #                   = dL/dy * b\n",
    "    def _backward():\n",
    "        a.grad += y.grad * b.data\n",
    "        b.grad += y.grad * a.data\n",
    "    y._backward = _backward\n",
    "\n",
    "    return y\n",
    "\n",
    "Scalar.__mul__ = __mul__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fa89249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kaitorch/core.py\n",
    "\n",
    "# Exponentiation\n",
    "def __pow__(a, b):\n",
    "\n",
    "    assert isinstance(b, (int, float)), \"Exponent is not int/float\"\n",
    "\n",
    "    # Calculation: y = a ** b\n",
    "    def _forward():\n",
    "        _a = a.data\n",
    "        _y = (_a + 1e-7) ** b  # don't divide by 0 :)\n",
    "        return Scalar(_y, _in=(a,), _op=f'**{b}')\n",
    "    y = _forward()\n",
    "\n",
    "    # Derivative: dy/da = b * (a ** (b-1))\n",
    "    # Chain Rule: dL/da = dL/dy * dy/da\n",
    "    #                   = dL/dy * b * (a ** (b-1))\n",
    "    def _backward():\n",
    "        a.grad += y.grad * (b * a.data ** (b - 1))\n",
    "    y._backward = _backward\n",
    "\n",
    "    return y\n",
    "\n",
    "Scalar.__pow__ = __pow__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8116a845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kaitorch/core.py\n",
    "\n",
    "# Natural Exponentiation\n",
    "def exp(a):\n",
    "\n",
    "    # Calculation: y = e ** a\n",
    "    def _forward():\n",
    "        _a = a.data\n",
    "        _y = math.exp(_a)\n",
    "        return Scalar(_y, _in=(a, ), _op='exp')\n",
    "    y = _forward()\n",
    "\n",
    "    # Derivative: dy/da = y\n",
    "    # Chain Rule: dL/da = dL/dy * dy/da\n",
    "    #                   = dL/dy * y\n",
    "    def _backward():\n",
    "        a.grad += y.grad * y.data\n",
    "    y._backward = _backward\n",
    "\n",
    "    return y\n",
    "\n",
    "Scalar.exp = exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb4c1286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kaitorch/core.py\n",
    "\n",
    "# Natural Log\n",
    "def log(a):\n",
    "\n",
    "    # Calculation: y = ln(a)\n",
    "    def _forward():\n",
    "        _a = a.data\n",
    "        _y = math.log(_a + 1e-8)\n",
    "\n",
    "        return Scalar(_y, _in=(a, ), _op='ln')\n",
    "    y = _forward()\n",
    "\n",
    "    # Derivative: dy/da = 1/a * a'\n",
    "    # Chain Rule: dL/da = dL/dy * dy/da * a'\n",
    "    #                   = dL/dy * 1/a * a'\n",
    "    def _backward():\n",
    "        a.grad += y.grad * ((a.data + 1e-8).__pow__(-1))\n",
    "    y._backward = _backward\n",
    "\n",
    "    return y\n",
    "\n",
    "Scalar.log = log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04985d45",
   "metadata": {},
   "source": [
    "__Note how `_forward()` is automatically called, but `_backward` isn't.__\n",
    "\n",
    "This is because we don't want to/can't calculate the derivatives during the forward pass. We just tell the `Scalar` to remember how to calculate the derivative, and then call it during the backward pass, once we have the loss value to calculate gradients with."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2599136",
   "metadata": {},
   "source": [
    "### What about Subtraction, Division, and Negatives?\n",
    "\n",
    "Remember that the calculation of these operations can be achieved by chaining the `_foward()` calculations of the base operators.\n",
    "\n",
    "Similarly, the derivative of these operations can be achieved by chaining the `_backward()` calculations of the base operators.\n",
    "\n",
    "\n",
    "And just as we can calculate the value of every node during the forward pass by starting from our inputs and propogating calculation results forward, we can calculate the derivative of every node during the backward pass by starting from our loss value and propogating the gradients backward!\n",
    "\n",
    "__Examples__\n",
    "\n",
    " - When we call `__neg__`, since it uses `__mul__`, it will use the `_backward()` of the `__mul__` operation.\n",
    "\n",
    " - When we call `__sub__`, since it uses `__neg__ -> __add__`, it will use the `_backward()` of `__add__ -> __mul__`\n",
    "\n",
    "Copying over all the other class methods from last notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ebfb6030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kaitorch/core.py\n",
    "\n",
    "def __radd__(a, b):\n",
    "\n",
    "    # b + a = a + b\n",
    "    return a.__add__(b)\n",
    "\n",
    "Scalar.__radd__ = __radd__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b232239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kaitorch/core.py\n",
    "\n",
    "def __rmul__(a, b):\n",
    "\n",
    "    # b * a = a * b\n",
    "    return a.__mul__(b)\n",
    "\n",
    "Scalar.__rmul__ = __rmul__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb570701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kaitorch/core.py\n",
    "\n",
    "def __neg__(a):\n",
    "\n",
    "    # -a = a * -1\n",
    "    return a.__mul__(-1)\n",
    "\n",
    "Scalar.__neg__ = __neg__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e7853fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kaitorch/core.py\n",
    "\n",
    "def __sub__(a, b):\n",
    "\n",
    "    # a - b = a + (b * -1)\n",
    "    return a.__add__(b.__neg__())\n",
    "\n",
    "def __rsub__(a, b):\n",
    "\n",
    "    # b - a = (a * -1) + b\n",
    "    return (a.__neg__()).__add__(b)\n",
    "\n",
    "Scalar.__sub__ = __sub__\n",
    "Scalar.__rsub__ = __rsub__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98cc6bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kaitorch/core.py\n",
    "\n",
    "def __truediv__(a, b):\n",
    "\n",
    "    # a / b = a * (b ** -1)\n",
    "    return a.__mul__((b + 1e-8).__pow__(-1)) # Avoid Division by 0\n",
    "\n",
    "def __rtruediv__(a, b):\n",
    "\n",
    "    # b / a = b * (a ** -1)\n",
    "    return Scalar(b).__mul__((a + 1e-8).__pow__(-1)) # Avoid Division by 0\n",
    "\n",
    "Scalar.__truediv__ = __truediv__\n",
    "Scalar.__rtruediv__ = __rtruediv__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a06477",
   "metadata": {},
   "source": [
    "# Topological Sort\n",
    "\n",
    "The last piece to finishing our implementation of reverse-mode autodiff is knowing in what order to calculate the gradients. We need to make sure that if \n",
    "\n",
    "$$ x \\Rightarrow y \\Rightarrow L $$\n",
    "\n",
    "That we calculate the derivative of $y$ before we calculate the derivative of $x$, since when using the chain rule, $\\nabla x$ depends on $\\nabla y$.\n",
    "\n",
    "The solution to this is a topological sort, where in a graph consisting of edges from `node x` to `node y`, in the sorted sequence `x` always comes before `y`. With the above example, a topological sort would (trivially) return `[x, y, L]`.\n",
    "\n",
    "Since we're doing a backward pass and we want to start from L, we simply reverse the topological sort to get the order in which we should calculate the derivatives, such that for each `node x` that is used to calculate `node y`,  $\\nabla y$ is calculated before $\\nabla x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "226b4f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kaitorch/core.py\n",
    "\n",
    "def backward(self):\n",
    "\n",
    "    topo = []\n",
    "    visited = set()\n",
    "\n",
    "    def build_topo(v):\n",
    "        if v not in visited:\n",
    "            visited.add(v)\n",
    "            for child in v._prev:\n",
    "                build_topo(child)\n",
    "            topo.append(v)\n",
    "    build_topo(self)\n",
    "\n",
    "    self.grad = 1.0\n",
    "    for node in reversed(topo):\n",
    "        node._backward()\n",
    "\n",
    "Scalar.backward = backward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea4978e",
   "metadata": {},
   "source": [
    "__That's it! ðŸ¥³ -__ we have everything we need to calculate the gradient of every node in a network now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f2ff888a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kaitorch.graph import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0628e511",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = Scalar(2.0)\n",
    "w1 = Scalar(-3.0)\n",
    "\n",
    "x2 = Scalar(0.0)\n",
    "w2 = Scalar(1.0)\n",
    "\n",
    "b = Scalar(13.5)\n",
    "\n",
    "x1w1 = x1*w1; x1w1.label = 'x1*w1'\n",
    "x2w2 = x2*w2; x2w2.label = 'x2*w2'\n",
    "\n",
    "x1w1x2w2 = x1w1 + x2w2; x1w1x2w2.label = 'x1*w1 + x2*w2'\n",
    "\n",
    "n = x1w1x2w2+b; n.label = 'n'\n",
    "\n",
    "n.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8b640ad1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 6.0.1 (20220911.1526)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"398pt\" height=\"520pt\"\n",
       " viewBox=\"0.00 0.00 397.50 520.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 516)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-516 393.5,-516 393.5,4 -4,4\"/>\n",
       "<!-- 140531202967104 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>140531202967104</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"0,-465.5 0,-511.5 82,-511.5 82,-465.5 0,-465.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"41\" y=\"-496.3\" font-family=\"Times,serif\" font-size=\"14.00\">data 1.0000</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"0,-488.5 82,-488.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"41\" y=\"-473.3\" font-family=\"Times,serif\" font-size=\"14.00\">grad 0.0000</text>\n",
       "</g>\n",
       "<!-- 140531474423280* -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>140531474423280*</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"141\" cy=\"-411\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"141\" y=\"-407.3\" font-family=\"Times,serif\" font-size=\"14.00\">*</text>\n",
       "</g>\n",
       "<!-- 140531202967104&#45;&gt;140531474423280* -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>140531202967104&#45;&gt;140531474423280*</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M70.19,-465.46C84.61,-454.57 101.84,-441.57 115.69,-431.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"117.95,-433.79 123.82,-424.97 113.73,-428.2 117.95,-433.79\"/>\n",
       "</g>\n",
       "<!-- 140531474423376 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>140531474423376</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"149.5,-155.5 149.5,-201.5 234.5,-201.5 234.5,-155.5 149.5,-155.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"192\" y=\"-186.3\" font-family=\"Times,serif\" font-size=\"14.00\">data &#45;6.0000</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"149.5,-178.5 234.5,-178.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"192\" y=\"-163.3\" font-family=\"Times,serif\" font-size=\"14.00\">grad 1.0000</text>\n",
       "</g>\n",
       "<!-- 140531474450800+ -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>140531474450800+</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"244\" cy=\"-101\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"244\" y=\"-97.3\" font-family=\"Times,serif\" font-size=\"14.00\">+</text>\n",
       "</g>\n",
       "<!-- 140531474423376&#45;&gt;140531474450800+ -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>140531474423376&#45;&gt;140531474450800+</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M207.32,-155.26C213.59,-146.16 220.85,-135.61 227.26,-126.31\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"230.29,-128.08 233.08,-117.86 224.52,-124.11 230.29,-128.08\"/>\n",
       "</g>\n",
       "<!-- 140531474423376+ -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>140531474423376+</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"192\" cy=\"-256\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"192\" y=\"-252.3\" font-family=\"Times,serif\" font-size=\"14.00\">+</text>\n",
       "</g>\n",
       "<!-- 140531474423376+&#45;&gt;140531474423376 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>140531474423376+&#45;&gt;140531474423376</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M192,-237.87C192,-230.18 192,-220.83 192,-211.9\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"195.5,-211.73 192,-201.73 188.5,-211.73 195.5,-211.73\"/>\n",
       "</g>\n",
       "<!-- 140531202966624 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>140531202966624</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"200,-465.5 200,-511.5 286,-511.5 286,-465.5 200,-465.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"243\" y=\"-496.3\" font-family=\"Times,serif\" font-size=\"14.00\">data 2.0000</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"200,-488.5 286,-488.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"243\" y=\"-473.3\" font-family=\"Times,serif\" font-size=\"14.00\">grad &#45;3.0000</text>\n",
       "</g>\n",
       "<!-- 140531202965904* -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>140531202965904*</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"243\" cy=\"-411\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"243\" y=\"-407.3\" font-family=\"Times,serif\" font-size=\"14.00\">*</text>\n",
       "</g>\n",
       "<!-- 140531202966624&#45;&gt;140531202965904* -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>140531202966624&#45;&gt;140531202965904*</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M243,-465.26C243,-457.18 243,-447.96 243,-439.49\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"246.5,-439.3 243,-429.3 239.5,-439.3 246.5,-439.3\"/>\n",
       "</g>\n",
       "<!-- 140531202965664 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>140531202965664</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"304.5,-465.5 304.5,-511.5 389.5,-511.5 389.5,-465.5 304.5,-465.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"347\" y=\"-496.3\" font-family=\"Times,serif\" font-size=\"14.00\">data &#45;3.0000</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"304.5,-488.5 389.5,-488.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"347\" y=\"-473.3\" font-family=\"Times,serif\" font-size=\"14.00\">grad 2.0000</text>\n",
       "</g>\n",
       "<!-- 140531202965664&#45;&gt;140531202965904* -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>140531202965664&#45;&gt;140531202965904*</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M316.64,-465.46C301.55,-454.5 283.49,-441.4 269.04,-430.9\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"270.71,-427.79 260.56,-424.75 266.6,-433.46 270.71,-427.79\"/>\n",
       "</g>\n",
       "<!-- 140531202967776 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>140531202967776</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"100,-465.5 100,-511.5 182,-511.5 182,-465.5 100,-465.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"141\" y=\"-496.3\" font-family=\"Times,serif\" font-size=\"14.00\">data 0.0000</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"100,-488.5 182,-488.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"141\" y=\"-473.3\" font-family=\"Times,serif\" font-size=\"14.00\">grad 1.0000</text>\n",
       "</g>\n",
       "<!-- 140531202967776&#45;&gt;140531474423280* -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>140531202967776&#45;&gt;140531474423280*</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M141,-465.26C141,-457.18 141,-447.96 141,-439.49\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"144.5,-439.3 141,-429.3 137.5,-439.3 144.5,-439.3\"/>\n",
       "</g>\n",
       "<!-- 140531202967872 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>140531202967872</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"252.5,-155.5 252.5,-201.5 339.5,-201.5 339.5,-155.5 252.5,-155.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"296\" y=\"-186.3\" font-family=\"Times,serif\" font-size=\"14.00\">data 13.5000</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"252.5,-178.5 339.5,-178.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"296\" y=\"-163.3\" font-family=\"Times,serif\" font-size=\"14.00\">grad 1.0000</text>\n",
       "</g>\n",
       "<!-- 140531202967872&#45;&gt;140531474450800+ -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>140531202967872&#45;&gt;140531474450800+</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M280.68,-155.26C274.41,-146.16 267.15,-135.61 260.74,-126.31\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"263.48,-124.11 254.92,-117.86 257.71,-128.08 263.48,-124.11\"/>\n",
       "</g>\n",
       "<!-- 140531474450800 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>140531474450800</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"203,-0.5 203,-46.5 285,-46.5 285,-0.5 203,-0.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"244\" y=\"-31.3\" font-family=\"Times,serif\" font-size=\"14.00\">data 7.5000</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"203,-23.5 285,-23.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"244\" y=\"-8.3\" font-family=\"Times,serif\" font-size=\"14.00\">grad 1.0000</text>\n",
       "</g>\n",
       "<!-- 140531474450800+&#45;&gt;140531474450800 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>140531474450800+&#45;&gt;140531474450800</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M244,-82.87C244,-75.18 244,-65.83 244,-56.9\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"247.5,-56.73 244,-46.73 240.5,-56.73 247.5,-56.73\"/>\n",
       "</g>\n",
       "<!-- 140531202965904 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>140531202965904</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"200.5,-310.5 200.5,-356.5 285.5,-356.5 285.5,-310.5 200.5,-310.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"243\" y=\"-341.3\" font-family=\"Times,serif\" font-size=\"14.00\">data &#45;6.0000</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"200.5,-333.5 285.5,-333.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"243\" y=\"-318.3\" font-family=\"Times,serif\" font-size=\"14.00\">grad 1.0000</text>\n",
       "</g>\n",
       "<!-- 140531202965904&#45;&gt;140531474423376+ -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>140531202965904&#45;&gt;140531474423376+</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M227.97,-310.26C221.83,-301.16 214.7,-290.61 208.42,-281.31\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"211.21,-279.19 202.71,-272.86 205.41,-283.11 211.21,-279.19\"/>\n",
       "</g>\n",
       "<!-- 140531202965904*&#45;&gt;140531202965904 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>140531202965904*&#45;&gt;140531202965904</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M243,-392.87C243,-385.18 243,-375.83 243,-366.9\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"246.5,-366.73 243,-356.73 239.5,-366.73 246.5,-366.73\"/>\n",
       "</g>\n",
       "<!-- 140531474423280 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>140531474423280</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"100,-310.5 100,-356.5 182,-356.5 182,-310.5 100,-310.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"141\" y=\"-341.3\" font-family=\"Times,serif\" font-size=\"14.00\">data 0.0000</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"100,-333.5 182,-333.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"141\" y=\"-318.3\" font-family=\"Times,serif\" font-size=\"14.00\">grad 1.0000</text>\n",
       "</g>\n",
       "<!-- 140531474423280&#45;&gt;140531474423376+ -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>140531474423280&#45;&gt;140531474423376+</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M156.03,-310.26C162.17,-301.16 169.3,-290.61 175.58,-281.31\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"178.59,-283.11 181.29,-272.86 172.79,-279.19 178.59,-283.11\"/>\n",
       "</g>\n",
       "<!-- 140531474423280*&#45;&gt;140531474423280 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>140531474423280*&#45;&gt;140531474423280</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M141,-392.87C141,-385.18 141,-375.83 141,-366.9\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"144.5,-366.73 141,-356.73 137.5,-366.73 144.5,-366.73\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7fcff86f0a00>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_model(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b597aba2",
   "metadata": {},
   "source": [
    "# Backpropogation\n",
    "\n",
    "Backpropogation is everything we've done so far - calculating the gradients of every parameter - with the added step of __updating the weights__ of our network. There are many ways to do this which we'll cover in the following notebooks.\n",
    "\n",
    "But before we do this, we'll want to to first implement a more \"proper\" neural network with Dense layers and talk about loss functions.\n",
    "\n",
    "__keep reading__ $\\Rightarrow$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
